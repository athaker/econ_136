{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Trump Election: An Introduction to Tensorflow\n",
    "This notebook demonstrates an introduction to Tensorflow for predicting the Trump victory for the 2016 \n",
    "presidential election, using stock market and 3rd party data. Through this guide you will utilize \n",
    "[tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) a library in Tensorflow that allows you to \n",
    "quickly build a fully connected neural network and train a model. \n",
    "Our input vectors will be a form of timeseries data.\n",
    "\n",
    "The following steps are performed:\n",
    "\n",
    "1. Files\n",
    "2. Preprocess timeseries features\n",
    "3. Play/Visualize the data\n",
    "4. Model: Predicting Trump Election\n",
    "5. Model: Predicting the market returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview \n",
    "The goal of this is to predict the winner of the 2016 Presidential Election using publicly available data at the time.  Instead of predicting the person to win we will phrase this problem as a binary classification task: predicting the political party that will win the election (Republican or Democratic). This will give us more data to sample from, hopefully improving the model performance. After that, we will use similar features to train another neural network which will be used to predict the market return after the election date. \n",
    "\n",
    "We have a small amount of data, overfitting and biases are a major problem. In practice you will have much more data. Using a GPU to accelerate the training time will be beneficial. A common GPU is the [Tesla K80 GPU](https://www.nvidia.com/en-us/data-center/tesla-k80/), and old but powerful and expensive GPU. \n",
    "\n",
    "You can use Google Colab, if you want to have more power at your fingertips, however, for brevity this will not be covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Files\n",
    "Here you will find two files: data.csv, djw.csv\n",
    "\n",
    "* **data.csv** contains historical data about presidential elections dating back until 1900.\n",
    "* **djw.csv** contains historical data about the [Dow Jones Industrial Average](https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average) for the daily close prices. \n",
    "Although this is an index, it can closely approximate the DIA ETF and other ETF's that track \"the market\". This was chosen due the large dataset size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess Data\n",
    "In this section we preprocess the data. Here we have to be careful that we do not inject forward looking bias. Therefore, we need to use the ```truncate``` command to get the nearest day before. The helper function below shows how to get the percentage return of the market given a dataframe of prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_pct(djw, index, days):\n",
    "    \"\"\" Computes a percentage change between a given day and some timedelta (days)\n",
    "    Args:\n",
    "        djw(PandasDataframe): contains index of prices and dates\n",
    "        index(datetime): day to search\n",
    "        days(int): numbers of days to search back\n",
    "    Returns:\n",
    "        (pct, int): percent change, and direction (1 positive, 0 negative)\n",
    "    \"\"\"\n",
    "    pct = None\n",
    "    ntd = djw.truncate(after=index).iloc[-1][\"Closing Value\"]\n",
    "    if days > 0:\n",
    "        pct = (djw[index:index + datetime.timedelta(days=1)].iloc[-1][\"Closing Value\"] - ntd) / \\\n",
    "              djw[index:index + datetime.timedelta(days=days)].iloc[-1][\"Closing Value\"]\n",
    "    else:\n",
    "        pct = (ntd - djw[index + datetime.timedelta(days=days):index].iloc[0][\"Closing Value\"]) / ntd\n",
    "    if pct > 0.0:\n",
    "        return pct, 1\n",
    "    else:\n",
    "        return pct, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert times to datetimes for easier processing. Pandas has great built in libraries that allow for quick data parsing. Pandas include a nice helper function called ```.to_datetime()``` which will automatically convert and figure out datetimes for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "djw = pd.read_csv(\"djw.csv\")  # Dow Jones Industrial Average Prices by Day\n",
    "djw = djw.set_index(pd.to_datetime(djw[\"Date\"]))  # Set the Datetime as index\n",
    "data = pd.read_csv(\"data.csv\")  # Read in 3rd party handlabeled data\n",
    "data = data.set_index(pd.to_datetime(data[\"date_elected\"]))  # Set the datetime as the index\n",
    "data = data[1:]  # We remove the first index to make sure we have enough data to look backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label out the features to sample. Here we believe that the market or some combination of the market features may predict the election. Id est: smart money might know where the election may go and invest accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could have been done in a list of lists but was made explicit for demonstration purposes\n",
    "day_before_1 = []  # 1 day before the election\n",
    "day_before_7 = []  # 7 days before the election\n",
    "day_before_30 = []  # 30 days before the election\n",
    "day_before_60 = []  # 60 days before the election\n",
    "day_before_180 = []  # 180 days before the election\n",
    "day_before_365 = []  # 365 days before the election\n",
    "day_before_730 = []  # 730 days before the election\n",
    "day_after_1 = []  # 1 day after the election\n",
    "day_after_7 = []  # 7 days after the election\n",
    "day_after_30 = []  # 30 days after the election\n",
    "day_after_60 = []  # 60 days after the election\n",
    "day_after_180 = []  # 180 days after the election\n",
    "day_after_365 = []  # 365 days after the election\n",
    "for index, row in data.iterrows():\n",
    "    day_after_1.append(\n",
    "        compute_td_pct(djw, index, 1)[1])  # Note here we are just getting the direction instead of the market change\n",
    "    day_after_7.append(compute_td_pct(djw, index, 7)[0])\n",
    "    day_after_30.append(compute_td_pct(djw, index, 30)[0])\n",
    "    day_after_60.append(compute_td_pct(djw, index, 60)[0])\n",
    "    day_after_180.append(compute_td_pct(djw, index, 180)[0])\n",
    "    day_after_365.append(compute_td_pct(djw, index, 365)[0])\n",
    "    day_before_1.append(compute_td_pct(djw, index, -1)[0])\n",
    "    day_before_7.append(compute_td_pct(djw, index, -7)[0])\n",
    "    day_before_30.append(compute_td_pct(djw, index, -30)[0])\n",
    "    day_before_60.append(compute_td_pct(djw, index, -60)[0])\n",
    "    day_before_180.append(compute_td_pct(djw, index, -180)[0])\n",
    "    day_before_365.append(compute_td_pct(djw, index, -365)[0])\n",
    "    day_before_730.append(compute_td_pct(djw, index, -730)[0])\n",
    "\n",
    "# Finally construct a DataFrame containing all of the data and add column labels and concat\n",
    "# the market data to the third party data\n",
    "market_data_cols = [day_before_1, day_before_7, day_before_30, day_before_60, day_before_180, day_before_365,\n",
    "                    day_before_730, day_after_1, day_after_7, day_after_30, day_after_60, day_after_180, day_after_365]\n",
    "market_data_col_names = [\"day_before_1\", \"day_before_7\", \"day_before_30\", \"day_before_60\", \"day_before_180\",\n",
    "                         \"day_before_365\", \"day_before_730\", \"day_after_1\", \"day_after_7\", \"day_after_30\",\n",
    "                         \"day_after_60\", \"day_after_180\", \"day_after_365\"]\n",
    "market_data = pd.DataFrame(market_data_cols).transpose()\n",
    "market_data.columns = market_data_col_names\n",
    "market_data = market_data.set_index(data.index)  # this operation is not inplace, use existing dataframe's index\n",
    "frames = [data, market_data]  # Pandas has some quirks unlike sql when concatenating\n",
    "combined_df = pd.concat(frames, axis=1)  # Axis 0 is after, 1 is next-to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Play/Visualize Data\n",
    "Now that we have preprocessed the data, take a look at the data and get a feel for how it is structured. You will note that there is not that much data, as it is hard to find reliable stock data in the early 1900's. \n",
    "\n",
    "Examine the features to get a sense of what they mean. \n",
    "* Party - 1 if Republican, 0 if Democratic\n",
    "* Previously Held Office - 1 if true\n",
    "* Previous Party - the party that was previously in power (goes back 2 terms), 1 if Republican, 0 if Democratic\n",
    "* Was VP or VP Runner - 1 if held the position of VP before the current election\n",
    "* day_before_n - percentage or direction of the market for a given number of days before the current election cycle but not including the day\n",
    "* day_after_n - percentage or direction of the market for a given number of days after the current election cycle\n",
    "\n",
    "When I actually did the prediction, I had much more data than just the above. I used [Google Trends](trends.google.com) to add more feature data. Furthermore, I added a \"sentiment analysis\" by looking through social media and other documents to get a feeling for the expected outcome. I strongly reccomend you include more features and more data than the 20+ elements we have here. More data the better. High quality data is important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             date_elected  party  prev_held_office  previous_party_1  \\\ndate_elected                                                           \n1904-11-08     1904-11-08      1                 0                 1   \n1908-11-03     1908-11-03      1                 0                 1   \n1912-11-05     1912-11-05      0                 0                 1   \n1916-11-07     1916-11-07      0                 1                 0   \n1920-11-02     1920-11-02      1                 0                 0   \n\n              previous_party_2  was_vp_or_vp_runner  day_before_1  \\\ndate_elected                                                        \n1904-11-08                   1                    1           0.0   \n1908-11-03                   1                    0           0.0   \n1912-11-05                   1                    0           0.0   \n1916-11-07                   1                    0           0.0   \n1920-11-02                   0                    0           0.0   \n\n              day_before_7  day_before_30  day_before_60  day_before_180  \\\ndate_elected                                                               \n1904-11-08        0.037526       0.112577       0.145979        0.276082   \n1908-11-03       -0.007904       0.028157      -0.007904        0.144574   \n1912-11-05       -0.000756      -0.040369      -0.009979        0.020714   \n1916-11-07        0.024251       0.065106       0.117340        0.159780   \n1920-11-02       -0.001521       0.002691      -0.030066       -0.101661   \n\n              day_before_365  day_before_730  day_after_1  day_after_7  \\\ndate_elected                                                             \n1904-11-08          0.363299        0.058144          1.0     0.012433   \n1908-11-03          0.294583       -0.141116          1.0     0.022454   \n1912-11-05          0.125038        0.050801          1.0     0.018333   \n1916-11-07          0.134409        0.490533          0.0    -0.003652   \n1920-11-02         -0.399392       -0.003042          0.0    -0.006130   \n\n              day_after_30  day_after_60  day_after_180  day_after_365  \ndate_elected                                                            \n1904-11-08        0.012648      0.012421       0.011290       0.010467  \n1908-11-03        0.022702      0.022785       0.022257       0.019613  \n1912-11-05        0.018795      0.018821       0.020826       0.021146  \n1916-11-07       -0.003570     -0.003952      -0.004201      -0.005312  \n1920-11-02       -0.006339     -0.006810      -0.006236      -0.006665  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_elected</th>\n      <th>party</th>\n      <th>prev_held_office</th>\n      <th>previous_party_1</th>\n      <th>previous_party_2</th>\n      <th>was_vp_or_vp_runner</th>\n      <th>day_before_1</th>\n      <th>day_before_7</th>\n      <th>day_before_30</th>\n      <th>day_before_60</th>\n      <th>day_before_180</th>\n      <th>day_before_365</th>\n      <th>day_before_730</th>\n      <th>day_after_1</th>\n      <th>day_after_7</th>\n      <th>day_after_30</th>\n      <th>day_after_60</th>\n      <th>day_after_180</th>\n      <th>day_after_365</th>\n    </tr>\n    <tr>\n      <th>date_elected</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1904-11-08</th>\n      <td>1904-11-08</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.037526</td>\n      <td>0.112577</td>\n      <td>0.145979</td>\n      <td>0.276082</td>\n      <td>0.363299</td>\n      <td>0.058144</td>\n      <td>1.0</td>\n      <td>0.012433</td>\n      <td>0.012648</td>\n      <td>0.012421</td>\n      <td>0.011290</td>\n      <td>0.010467</td>\n    </tr>\n    <tr>\n      <th>1908-11-03</th>\n      <td>1908-11-03</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-0.007904</td>\n      <td>0.028157</td>\n      <td>-0.007904</td>\n      <td>0.144574</td>\n      <td>0.294583</td>\n      <td>-0.141116</td>\n      <td>1.0</td>\n      <td>0.022454</td>\n      <td>0.022702</td>\n      <td>0.022785</td>\n      <td>0.022257</td>\n      <td>0.019613</td>\n    </tr>\n    <tr>\n      <th>1912-11-05</th>\n      <td>1912-11-05</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-0.000756</td>\n      <td>-0.040369</td>\n      <td>-0.009979</td>\n      <td>0.020714</td>\n      <td>0.125038</td>\n      <td>0.050801</td>\n      <td>1.0</td>\n      <td>0.018333</td>\n      <td>0.018795</td>\n      <td>0.018821</td>\n      <td>0.020826</td>\n      <td>0.021146</td>\n    </tr>\n    <tr>\n      <th>1916-11-07</th>\n      <td>1916-11-07</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.024251</td>\n      <td>0.065106</td>\n      <td>0.117340</td>\n      <td>0.159780</td>\n      <td>0.134409</td>\n      <td>0.490533</td>\n      <td>0.0</td>\n      <td>-0.003652</td>\n      <td>-0.003570</td>\n      <td>-0.003952</td>\n      <td>-0.004201</td>\n      <td>-0.005312</td>\n    </tr>\n    <tr>\n      <th>1920-11-02</th>\n      <td>1920-11-02</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-0.001521</td>\n      <td>0.002691</td>\n      <td>-0.030066</td>\n      <td>-0.101661</td>\n      <td>-0.399392</td>\n      <td>-0.003042</td>\n      <td>0.0</td>\n      <td>-0.006130</td>\n      <td>-0.006339</td>\n      <td>-0.006810</td>\n      <td>-0.006236</td>\n      <td>-0.006665</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "combined_df.head() # gives the top 5, can use tail to give the last 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           party  prev_held_office  previous_party_1  previous_party_2  \\\ncount  29.000000         29.000000         29.000000         29.000000   \nmean    0.517241          0.344828          0.517241          0.551724   \nstd     0.508548          0.483725          0.508548          0.506120   \nmin     0.000000          0.000000          0.000000          0.000000   \n25%     0.000000          0.000000          0.000000          0.000000   \n50%     1.000000          0.000000          1.000000          1.000000   \n75%     1.000000          1.000000          1.000000          1.000000   \nmax     1.000000          1.000000          1.000000          1.000000   \n\n       was_vp_or_vp_runner  day_before_1  day_before_7  day_before_30  \\\ncount            29.000000     29.000000     29.000000      29.000000   \nmean              0.379310      0.002016      0.014532       0.016543   \nstd               0.493804      0.006578      0.017648       0.037084   \nmin               0.000000     -0.002982     -0.011032      -0.040369   \n25%               0.000000      0.000000      0.000000      -0.011044   \n50%               0.000000      0.000000      0.013861       0.012609   \n75%               1.000000      0.000000      0.020732       0.035039   \nmax               1.000000      0.031734      0.067513       0.112577   \n\n       day_before_60  day_before_180  day_before_365  day_before_730  \\\ncount      29.000000       29.000000       29.000000       29.000000   \nmean        0.005033        0.043755        0.040059        0.089520   \nstd         0.064675        0.110046        0.232439        0.376834   \nmin        -0.179777       -0.336769       -0.808455       -1.657169   \n25%        -0.022993       -0.012496        0.023558        0.052363   \n50%         0.013489        0.042738        0.096108        0.145892   \n75%         0.029554        0.114063        0.144247        0.230675   \nmax         0.145979        0.276082        0.363299        0.490533   \n\n       day_after_1  day_after_7  day_after_30  day_after_60  day_after_180  \\\ncount    29.000000    29.000000     29.000000     29.000000      29.000000   \nmean      0.448276    -0.002882     -0.003152     -0.002937      -0.002924   \nstd       0.506120     0.019684      0.020203      0.019460       0.019455   \nmin       0.000000    -0.055902     -0.058022     -0.053794      -0.059180   \n25%       0.000000    -0.009059     -0.009004     -0.008936      -0.008607   \n50%       0.000000    -0.001941     -0.001941     -0.001933      -0.001832   \n75%       1.000000     0.011486      0.011080      0.010250       0.010074   \nmax       1.000000     0.022454      0.022702      0.022785       0.022876   \n\n       day_after_365  \ncount      29.000000  \nmean       -0.002029  \nstd         0.018122  \nmin        -0.049582  \n25%        -0.008056  \n50%        -0.001758  \n75%         0.010467  \nmax         0.030659  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>party</th>\n      <th>prev_held_office</th>\n      <th>previous_party_1</th>\n      <th>previous_party_2</th>\n      <th>was_vp_or_vp_runner</th>\n      <th>day_before_1</th>\n      <th>day_before_7</th>\n      <th>day_before_30</th>\n      <th>day_before_60</th>\n      <th>day_before_180</th>\n      <th>day_before_365</th>\n      <th>day_before_730</th>\n      <th>day_after_1</th>\n      <th>day_after_7</th>\n      <th>day_after_30</th>\n      <th>day_after_60</th>\n      <th>day_after_180</th>\n      <th>day_after_365</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.517241</td>\n      <td>0.344828</td>\n      <td>0.517241</td>\n      <td>0.551724</td>\n      <td>0.379310</td>\n      <td>0.002016</td>\n      <td>0.014532</td>\n      <td>0.016543</td>\n      <td>0.005033</td>\n      <td>0.043755</td>\n      <td>0.040059</td>\n      <td>0.089520</td>\n      <td>0.448276</td>\n      <td>-0.002882</td>\n      <td>-0.003152</td>\n      <td>-0.002937</td>\n      <td>-0.002924</td>\n      <td>-0.002029</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.508548</td>\n      <td>0.483725</td>\n      <td>0.508548</td>\n      <td>0.506120</td>\n      <td>0.493804</td>\n      <td>0.006578</td>\n      <td>0.017648</td>\n      <td>0.037084</td>\n      <td>0.064675</td>\n      <td>0.110046</td>\n      <td>0.232439</td>\n      <td>0.376834</td>\n      <td>0.506120</td>\n      <td>0.019684</td>\n      <td>0.020203</td>\n      <td>0.019460</td>\n      <td>0.019455</td>\n      <td>0.018122</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.002982</td>\n      <td>-0.011032</td>\n      <td>-0.040369</td>\n      <td>-0.179777</td>\n      <td>-0.336769</td>\n      <td>-0.808455</td>\n      <td>-1.657169</td>\n      <td>0.000000</td>\n      <td>-0.055902</td>\n      <td>-0.058022</td>\n      <td>-0.053794</td>\n      <td>-0.059180</td>\n      <td>-0.049582</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.011044</td>\n      <td>-0.022993</td>\n      <td>-0.012496</td>\n      <td>0.023558</td>\n      <td>0.052363</td>\n      <td>0.000000</td>\n      <td>-0.009059</td>\n      <td>-0.009004</td>\n      <td>-0.008936</td>\n      <td>-0.008607</td>\n      <td>-0.008056</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.013861</td>\n      <td>0.012609</td>\n      <td>0.013489</td>\n      <td>0.042738</td>\n      <td>0.096108</td>\n      <td>0.145892</td>\n      <td>0.000000</td>\n      <td>-0.001941</td>\n      <td>-0.001941</td>\n      <td>-0.001933</td>\n      <td>-0.001832</td>\n      <td>-0.001758</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.020732</td>\n      <td>0.035039</td>\n      <td>0.029554</td>\n      <td>0.114063</td>\n      <td>0.144247</td>\n      <td>0.230675</td>\n      <td>1.000000</td>\n      <td>0.011486</td>\n      <td>0.011080</td>\n      <td>0.010250</td>\n      <td>0.010074</td>\n      <td>0.010467</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.031734</td>\n      <td>0.067513</td>\n      <td>0.112577</td>\n      <td>0.145979</td>\n      <td>0.276082</td>\n      <td>0.363299</td>\n      <td>0.490533</td>\n      <td>1.000000</td>\n      <td>0.022454</td>\n      <td>0.022702</td>\n      <td>0.022785</td>\n      <td>0.022876</td>\n      <td>0.030659</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "combined_df.describe() # statistics about the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model: Predicting the Trump Election\n",
    "Here we will train a DNN that aims to predict the 2016 Presidential Election. The features will be the features explored above (except for the forward looking ones). You do not need to fully understand how a [neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network) works, however it can be thought of mapping inputs to outputs and the network will figure out everything inbetween. The aim is to not have the best network architecture possible, but to leverage neural network's ability to find patterns among data that otherwise would be difficult or timeconsuming to find by pure inspection. \n",
    "\n",
    "We are using Deep Learning to figure out the useful features and generate a model based upon those useful features to predict upon. \n",
    "\n",
    "Tensorflow is the selected Deep Learning framework, as it tends to be the most popular in industry. There are many others and each has a different purpose and use. Use what is best to get the job done.\n",
    "* CNTK (Microsoft Cognitive Toolkit)\n",
    "* Keras - this actually is a high level API that has general calls to other frameworks\n",
    "* Theano\n",
    "* Torch\n",
    "* Caffe/Caffe2\n",
    "* Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our goal is to predict the party that will win the election\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Softmax\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the relevant features and labels that we are trying to predict. The market prices and the presidential data. Here we will be having a MIMO (Multi Input Multi Output) problem where we will predict not only the expected winner, but also the expected market direction.\n",
    "\n",
    "    X - Our features\n",
    "    y - our labels (what we want to predict)\n",
    "\n",
    "Ensure that we are not encoding data that may have forward looking bias. Thank you @Justin Jiang <jbjiang@g.hmc.edu> for catching this bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[[\"prev_held_office\", \"was_vp_or_vp_runner\"]] = combined_df[[\"prev_held_office\", \"was_vp_or_vp_runner\"]].shift(1).fillna(0)\n",
    "\n",
    "X = combined_df[['prev_held_office', 'previous_party_1',\n",
    "       'previous_party_2', 'was_vp_or_vp_runner', 'day_before_1',\n",
    "       'day_before_7', 'day_before_30', 'day_before_60', 'day_before_180',\n",
    "       'day_before_365', 'day_before_730']]\n",
    "\n",
    "\n",
    "y = combined_df[[\"party\", \"day_after_1\", \"day_after_7\", \"day_after_30\",\n",
    "                         \"day_after_60\", \"day_after_180\", \"day_after_365\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the data into a test and training set. Note, we will be only having one value for testing as this is what we want to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:-1]\n",
    "y_train = y.iloc[:-1]\n",
    "X_test  = X.iloc[-1:]\n",
    "y_test  = y.iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can build our model. Here we are using the `Sequential` library. Later you should explore the `Functional`. We are simply using a feedforward network that is fully connected with relu activations. This is to show that a simple network can be quite powerful with high quaility data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=len(X.columns)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(len(y.columns)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile the model and see how we do! Note: in the fitting process we are holding out the last 20% of the data to ensure that we are not overfitting. We want to perform about the same as we do on the training set as the testing set. Production models that have an extremely limited amount of training data will often be retrained with the whole dataset to allow for better model. This is done after we have decided upon a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\nWARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n1/1 [==============================] - 0s 791us/sample - loss: 0.0681 - mae: 0.1958\n"
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=sgd,metrics=[\"mae\"])\n",
    "hist = model.fit(X_train, y_train, epochs=200, verbose=0, validation_split=0.1)\n",
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 actual  predicted\nparty          1.000000   0.582241\nday_after_1    1.000000   0.507118\nday_after_7    0.013579   0.048224\nday_after_30   0.013100  -0.178125\nday_after_60   0.012871  -0.092291\nday_after_180  0.012232  -0.021258\nday_after_365  0.010905   0.106571",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>party</th>\n      <td>1.000000</td>\n      <td>0.582241</td>\n    </tr>\n    <tr>\n      <th>day_after_1</th>\n      <td>1.000000</td>\n      <td>0.507118</td>\n    </tr>\n    <tr>\n      <th>day_after_7</th>\n      <td>0.013579</td>\n      <td>0.048224</td>\n    </tr>\n    <tr>\n      <th>day_after_30</th>\n      <td>0.013100</td>\n      <td>-0.178125</td>\n    </tr>\n    <tr>\n      <th>day_after_60</th>\n      <td>0.012871</td>\n      <td>-0.092291</td>\n    </tr>\n    <tr>\n      <th>day_after_180</th>\n      <td>0.012232</td>\n      <td>-0.021258</td>\n    </tr>\n    <tr>\n      <th>day_after_365</th>\n      <td>0.010905</td>\n      <td>0.106571</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "out = model.predict(X_test)\n",
    "results = pd.DataFrame([y_test.values.flatten(), out.flatten()], columns=y_test.keys().values.tolist()).transpose()\n",
    "results.columns = [\"actual\", \"predicted\"]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicting a Trump Victory\nPredicting the market will be up.\n"
    }
   ],
   "source": [
    "if results[\"predicted\"].party > 0.5:\n",
    "    print(\"Predicting a Trump Victory\")\n",
    "else:\n",
    "    print(\"Predicting a Clinton Victory\")\n",
    "\n",
    "if results[\"predicted\"][\"day_after_1\"] > 0.5:\n",
    "    print(\"Predicting the market will be up.\")\n",
    "else:\n",
    "    print(\"Predicting the market will be down.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we were correct! We have correctly predicted the candidate to be elected, and the direction of the market return. Maybe play with some hyperparameters to improve the model. Be careful of overfitting given we have a tiny dataset.\n",
    "\n",
    "Also try running this notebook multiple times, you may notice that you will get different results each time. This is due to the inherit random nature of neural networks upon initilization. Why is this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For next steps, try what you expect will happen in the 2020 election?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python_defaultSpec_1595489350984"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}